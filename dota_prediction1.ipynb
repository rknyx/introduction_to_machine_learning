{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# data = pd.read_csv('features.csv', index_col='match_id')\n",
    "# X_train = data.loc[:, 'start_time':'dire_first_ward_time'] # Drop information about future after 5 minutes passed\n",
    "\n",
    "# columns_with_NANs = pd.isnull(X_train).any()[pd.isnull(X_train).any() == True].keys() # All columns with missing values\n",
    "# print(\" \".join(columns_with_NANs))\n",
    "\n",
    "\"\"\"\n",
    "1.1 Следующие признаки имеют пропуски в своих значениях: first_blood_time, first_blood_team, first_blood_player1,\n",
    "first_blood_player2, radiant_bottle_time, radiant_courier_time, radiant_flying_courier_time, radiant_first_ward_time,\n",
    "dire_bottle_time, dire_courier_time, dire_flying_courier_time, dire_first_ward_time. Очень просто объяснить пропущенные\n",
    "значения в признаках first_blood_time и first_blood_team: эти пропуски обусловелны тем, что в течение первых 5 минут \n",
    "игры не произошло события First Blood, т. е. никто никого не убил.\n",
    "\"\"\"\n",
    "\n",
    "X_train_zeros = X_train.fillna(0)                # Filling missing values with zeros\n",
    "X_train_infs = X_train.fillna(10**20)            # Filling missing values with big values  \n",
    "X_train_means = X_train.fillna(X_train.mean())   # Filling missing values with mean values\n",
    "\n",
    "y_train = data['radiant_win']\n",
    "\n",
    "\"\"\"\n",
    "1.2 Столбец, содержащий целевую переменную называется radiant_win.   \n",
    "\"\"\"\n",
    "\n",
    "kf = KFold(X_train.shape[0], n_folds=5, shuffle=True, random_state=1)\n",
    "\n",
    "result = []\n",
    "for X in [X_train_zeros, X_train_infs, X_train_means]:\n",
    "    scores = {}\n",
    "    times = {}\n",
    "    for n in [10, 20, 30, 250]:\n",
    "        start_time = time.time()\n",
    "        clf = GradientBoostingClassifier(n_estimators=n, random_state=241)\n",
    "        scores[n] = cross_val_score(clf, X, y_train, cv=kf, scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "        end_time = time.time()\n",
    "        times[n] = end_time - start_time\n",
    "    result.append([scores, times])\n",
    "print(result)\n",
    "\n",
    "\"\"\"\n",
    "1.3 Кросс-валидация для градиентного бустинга с 30 деревьями проводилась 71 секунду, при этом, получившееся\n",
    "качество ROC-AUC score составило 0.68990.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "1.4 На мой взгляд есть смылсл пробовать брать больше 30 деревьев в градиентном бустинге. Например, когда я попробовал \n",
    "взять 250 деревьев, я получил оценку качества равную 0.71588. Для того, чтобы уменьшить время обичения при большом \n",
    "количестве деревьев можно уменьшать максимальную глубину деревьев или вместо всей обучающей выборки использовать\n",
    "только её часть.\n",
    "\"\"\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_zeros_scaled = scaler.fit_transform(X_train_zeros)     \n",
    "X_train_infs_scaled = scaler.fit_transform(X_train_infs)\n",
    "X_train_means_scaled = scaler.fit_transform(X_train_means)\n",
    "\n",
    "def LogReg(X1, X2, X3):\n",
    "    result = []\n",
    "    for X in [X1, X2, X3]:\n",
    "        scores = {}\n",
    "        times = {}\n",
    "        for C in [0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300]:\n",
    "            start_time = time.time()\n",
    "            clf = LogisticRegression(C=C)\n",
    "            scores[C] = cross_val_score(clf, X, y_train, cv=kf, scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "            end_time = time.time()\n",
    "            times[C] = end_time - start_time\n",
    "        result.append([scores, times])\n",
    "    return result\n",
    "\n",
    "result = LogReg(X_train_zeros_scaled, X_train_infs_scaled, X_train_means_scaled)\n",
    "print(result)\n",
    "\n",
    "\"\"\"\n",
    "2.1 Для данной модели наилучшее качество получилось при замене всех пропусков в признаках на их средние значения. \n",
    "При этом качество составило 0.71677. На качество предсказаний очень слабо вляет параметр \"C\" регуляризации, отличия\n",
    "в качестве наблюдаются только в 3 знаке после запятой. Тем не менее наибольшего качества модель достигает при \n",
    "значении параметра C=0.003. Очевидна разница показателей качества при решении задачи с использованием градиентного\n",
    "бустинга и логистической регрессии. Для 30 деревьев в градинтном бустинге эта разница составляет почти 3 процента.\n",
    "Я думаю это связано с тем, что 30 деревьев мало и модель градиентного бустинга оказывается недообученной. Помимо\n",
    "прочего логистическая регрессия работает заметно быстрее в сравнении с градиентным бустингом. Разница во времени\n",
    "для модели логистической регрессии с наилучшим параметром C и модели градиентного бустинга с 30 деревьями составила\n",
    "52 секунды.  \n",
    "\"\"\"\n",
    "\n",
    "X_all = []\n",
    "for X in [X_train_zeros, X_train_infs, X_train_means]:   \n",
    "    X = X.drop(X_train_zeros[['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                                            'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']], 1)\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_all.append(X_scaled)\n",
    "X_train_zeros_scaled, X_train_infs_scaled, X_train_means_scaled = X_all\n",
    "\n",
    "result = LogReg(X_train_zeros_scaled, X_train_infs_scaled, X_train_means_scaled)\n",
    "print(result)\n",
    "\n",
    "\"\"\"\n",
    "2.2 При изъятии категориальных признаков качество модели практически не изменилось. Максимальное значение качества\n",
    "по-прежнему достигается при значении параметра C=0.003 и составляетс 0.71681. На мой взгляд этот факт объясняется\n",
    "тем, что в \"сыром\" виде данные признаки не несут како-либо существенной информации, а лишь вносят дополнительные шумы. \n",
    "Необходимо смотреть на статистику всех героев в целом: какой герой, как часто выигрывает и т.д.\n",
    "\"\"\"\n",
    "\n",
    "heroes = X_train_zeros[['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                          'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']]\n",
    "idents = set()\n",
    "for column in heroes.columns:\n",
    "    idents |= set(heroes[column].values)\n",
    "print(len(idents))\n",
    "    \n",
    "\"\"\"\n",
    "2.3 В данной игре существует 108 различных идентификаторов героев.\n",
    "\"\"\"\n",
    "\n",
    "X_pick = sp.zeros((X_train.shape[0], len(idents)))\n",
    "dict_idents = {ident: ind for ind, ident in zip(range(len(idents)), idents)}\n",
    "for i, match_id in enumerate(X_train.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, dict_idents[data.ix[match_id, 'r%d_hero' % (p+1)]]] = 1\n",
    "        X_pick[i, dict_idents[data.ix[match_id, 'd%d_hero' % (p+1)]]] = -1\n",
    "        \n",
    "X_train_zeros_scaled = sp.hstack((sp.array(X_train_zeros_scaled), X_pick))\n",
    "X_train_infs_scaled = sp.hstack((sp.array(X_train_infs_scaled), X_pick))\n",
    "X_train_means_scaled = sp.hstack((sp.array(X_train_means_scaled), X_pick))\n",
    "\n",
    "result = LogReg(X_train_zeros_scaled, X_train_infs_scaled, X_train_means_scaled)\n",
    "print(result)\n",
    "\n",
    "\"\"\"\n",
    "2.4 При dummy кодировании качество модели заметно повысилось и составило 0.75195, при этом наилучший параметр \n",
    "регуляризации составил C=0.1. Это объясняется тем, что теперь алгоритм получил важную информацию о героях,\n",
    "смог учесть частоту побед тех или иных героев.\n",
    "\"\"\"\n",
    "\n",
    "X_test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "X_test_means = X_test.fillna(X_test.mean())\n",
    "X_test_means = X_test_means.drop(X_test_means[['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                                                             'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']], 1)\n",
    "X_test_means_scaled = scaler.fit_transform(X_test_means)\n",
    "X_pick_test = sp.zeros((X_test.shape[0], len(idents)))\n",
    "for i, match_id in enumerate(X_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick_test[i, dict_idents[X_test.ix[match_id, 'r%d_hero' % (p+1)]]] = 1\n",
    "        X_pick_test[i, dict_idents[X_test.ix[match_id, 'd%d_hero' % (p+1)]]] = -1\n",
    "X_test_means_scaled = sp.hstack((sp.array(X_test_means_scaled), X_pick_test))\n",
    "clf_final = LogisticRegression(C=0.1)\n",
    "clf_final.fit(X_train_means_scaled, y_train)\n",
    "pred = clf_final.predict_proba(X_test_means_scaled)[:, 1]\n",
    "min_pred, max_pred = min(pred), max(pred)\n",
    "print(min_pred, max_pred)\n",
    "\n",
    "\"\"\"\n",
    "2.5 Максимальное значение прогноза на тестовой выборке равно 0.99644. Минимальное значение прогноза на тестовой\n",
    "выборке равно 0.00870.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
