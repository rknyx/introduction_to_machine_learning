{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from numpy import delete\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "data = pandas.read_csv('~/submissions/gradient_busting/gbm-data.csv')\n",
    "numpy_data = data.values\n",
    "y = data['Activity']\n",
    "columns = data.columns.values\n",
    "\n",
    "x = data[delete(columns, 0)]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.8, random_state=241)\n",
    "\n",
    "test_score = []\n",
    "\n",
    "# for learning_rate in [1, 0.5, 0.3, 0.2, 0.1]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec learning rate :0.2\n",
      "start to fit\n",
      "start to calc staged decision train for rate: 0.2\n",
      "start to calc staged decision test for rate: 0.2\n"
     ]
    }
   ],
   "source": [
    "vectorized_sigmoid = np.vectorize(sigmoid)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for learning_rate in [1, 0.5, 0.3, 0.2, 0.1]:\n",
    "for learning_rate in [0.2]:\n",
    "    print \"exec learning rate :%s\" % learning_rate\n",
    "    classifier = GradientBoostingClassifier(n_estimators=250, random_state=241, learning_rate=learning_rate)\n",
    "    \n",
    "    print \"start to fit\"\n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    print \"start to calc staged decision train for rate: %s\" % learning_rate\n",
    "    sigmoid_predicted_y_train = [vectorized_sigmoid(x) for x in classifier.staged_decision_function(x_train)]\n",
    "    print \"start to calc staged decision test for rate: %s\" % learning_rate\n",
    "    sigmoid_predicted_y_test = [vectorized_sigmoid(x) for x in classifier.staged_decision_function(x_test)]\n",
    "\n",
    "    logloss_train = [log_loss(y_true=y_train, y_pred=val) for val in sigmoid_predicted_y_train]\n",
    "    logloss_test = [log_loss(y_true=y_test, y_pred=val) for val in sigmoid_predicted_y_test]\n",
    "    \n",
    "#     plt.plot(range(1, len(logloss_train) + 1), logloss_train, label=\"train, rate: '%s'\" % learning_rate)\n",
    "#     plt.plot(range(1, len(logloss_test) + 1), logloss_test, label=\"test, rate: '%s'\" % learning_rate)\n",
    "\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('estimators')\n",
    "# plt.legend()  \n",
    "# plt.show()\n",
    "\n",
    "# with open('/home/rk/submissions/gradient_busting/res1.txt', 'w') as f:\n",
    "#     f.write('overfitting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "val = 200\n",
    "for i in xrange(0, len(logloss_test)):\n",
    "    if logloss_test[i] < val:\n",
    "        val = logloss_test[i]\n",
    "        num = i\n",
    "num, val, logloss_test[num]\n",
    "num = num + 1\n",
    "with open('/home/rk/submissions/gradient_busting/res2.txt', 'w') as f:\n",
    "    f.write('0.53 %s' % num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=37, n_jobs=1,\n",
       "            oob_score=False, random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_classifier = RandomForestClassifier(n_estimators=37, random_state=241)\n",
    "forest_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest_prediction = forest_classifier.predict_proba(x_test)\n",
    "log_loss_forest = log_loss(y_true=y_test, y_pred=forest_prediction)\n",
    "log_loss_forest\n",
    "with open('/home/rk/submissions/gradient_busting/res3.txt', 'w') as f:\n",
    "    f.write('0.54')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
